{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:38.127067100Z",
     "start_time": "2023-06-22T17:05:38.098187500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.optim import RMSprop, Adam, SGD\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import product\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"2_NN_outputs/\"\n",
    "model_dir = base_dir + \"models/\"\n",
    "runs_dir = base_dir + \"runs/\"\n",
    "\n",
    "# shutil.rmtree(model_dir, ignore_errors=True)\n",
    "# shutil.rmtree(runs_dir, ignore_errors=True)\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "# os.makedirs(runs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, fix all the seeds\n",
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # Save X and y as Tensors, accordingly to the type of the data\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "\n",
    "        self.num_features = X.shape[1]\n",
    "\n",
    "    # Dataset size\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx, :], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.070805500Z",
     "start_time": "2023-06-22T17:05:42.065927700Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetworkSimple(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, depth):\n",
    "        super(NeuralNetworkSimple, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*[nn.Linear(hidden_size, hidden_size), nn.ReLU()] * (depth - 1))\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_in = self.input_layer(x)\n",
    "        h_out = self.hidden_layers(h_in)\n",
    "        out = self.output(h_out)\n",
    "        return out\n",
    "\n",
    "    def _get_description(self):\n",
    "        return \"[Linear(hidden_size)+ReLU]*depth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkDropout(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, depth, dropout_rate):\n",
    "        super(NeuralNetworkDropout, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            *[nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Dropout(dropout_rate)] * (depth - 1)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_in = self.input_layer(x)\n",
    "        h_out = self.hidden_layers(h_in)\n",
    "        out = self.output(h_out)\n",
    "        return out\n",
    "\n",
    "    def _get_description(self):\n",
    "        return \"[Linear(hidden_size)+ReLU+Dropout(dropout_rate)]*depth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, delta=0):\n",
    "        self.patience: int = patience\n",
    "        self.delta: int = delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float(\"inf\")\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss <= (self.min_validation_loss - self.delta):\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            # print(\"\\tEarly stopper: {}/{} epochs\".format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.116054200Z",
     "start_time": "2023-06-22T17:05:42.087104900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for the training process\n",
    "def train_model(\n",
    "    model: nn.Module,  # instance of class to train\n",
    "    criterion,  # instance of loss function\n",
    "    optimizer,  # instance of optimizer\n",
    "    epochs,  # number of\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    scheduler,\n",
    "    early_stopper,\n",
    "    device,  # to train on\n",
    "    log_writer,\n",
    "    log_name,\n",
    "):\n",
    "    n_iter = 0\n",
    "    best_valid_loss = float(\"inf\")  # initialized to worst possible value\n",
    "\n",
    "    # EPOCHS\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # activate training mode (for BatchNorm or Dropout)\n",
    "\n",
    "        # BATCHES\n",
    "        for data, targets in train_loader:  # get_item from MyDataset class (single item or batch)\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # gradient to zero\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(data)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred.squeeze(), targets)  # reshape because MSELoss requires same dimensionality\n",
    "            log_writer.add_scalar(\"Loss train/batches\", loss, n_iter)  # plot the batches\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "        # Valuation\n",
    "        y_test, y_pred = test_model(model, val_loader, device)\n",
    "        loss_val = criterion(y_pred.squeeze(), y_test)\n",
    "        log_writer.add_scalar(\"Loss val/epochs\", loss_val, epoch)  # plot the epochs\n",
    "\n",
    "        scheduler.step(loss_val)\n",
    "\n",
    "        # Save the model with best loss through the epochs\n",
    "        if loss_val.item() < best_valid_loss:\n",
    "            best_valid_loss = loss_val.item()\n",
    "            torch.save(model.state_dict(), model_dir + log_name)\n",
    "\n",
    "        # Early Stopping\n",
    "        if early_stopper.early_stop(loss_val.item()):\n",
    "            print(\"Early stopped!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.116054200Z",
     "start_time": "2023-06-22T17:05:42.106079700Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model: nn.Module, data_loader: DataLoader, device) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    model.eval()  # activate evaluation mode (for BatchNorm or Dropout)\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "\n",
    "    for data, targets in data_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        y_pred.append(model(data))  # accumulate predictions\n",
    "        y_test.append(targets)  # accumulate labels\n",
    "\n",
    "    y_test = torch.stack(y_test).squeeze()\n",
    "    y_pred = torch.stack(y_pred).squeeze()\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:40.242589800Z",
     "start_time": "2023-06-22T17:05:38.117070300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  252123\n",
      "Columns:  91\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\").drop_duplicates()\n",
    "print(\"Rows: \", df.shape[0])\n",
    "print(\"Columns: \", df.shape[1])\n",
    "\n",
    "df_X = df.iloc[:, 1:].values\n",
    "df_y = df.iloc[:, 0].values\n",
    "indices = np.arange(df_X.shape[0])\n",
    "\n",
    "# Separate indices in train/val/set\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.3, stratify=df_y, random_state=random_state)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.2, stratify=df_y[train_idx], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.056143500Z",
     "start_time": "2023-06-22T17:05:40.565714200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.covariance import OAS\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipeline = Pipeline([(\"raw\", None)])\n",
    "# preprocess_name = \"RAW\"\n",
    "\n",
    "# pipeline = Pipeline(steps=[(\"min-max\", preprocessing.MinMaxScaler())])\n",
    "# preprocess_name = \"MinMax\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"std\", preprocessing.StandardScaler()),\n",
    "        (\"l2\", preprocessing.Normalizer(norm=\"l2\")),\n",
    "    ]\n",
    ")\n",
    "preprocess_name = \"STD+L2\"\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"min-max\", preprocessing.MinMaxScaler()),\n",
    "#         (\"lmax\", preprocessing.Normalizer(norm=\"max\")),\n",
    "#         (\"lda\", LinearDiscriminantAnalysis(solver=\"eigen\", shrinkage=None, covariance_estimator=OAS())),\n",
    "#     ]\n",
    "# )\n",
    "# preprocess_name = \"MinMax+Lmax+LDA\"\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\"min-max\", preprocessing.MinMaxScaler()),\n",
    "#         (\"lda\", LinearDiscriminantAnalysis(solver=\"eigen\", covariance_estimator=OAS())),\n",
    "#         (\"nys\", Nystroem(random_state=random_state, n_jobs=-1, gamma=0.010, n_components=1000)),\n",
    "#     ]\n",
    "# )\n",
    "# preprocess_name = \"MinMax+LDA+NYS\"\n",
    "\n",
    "pipeline.fit(df_X[train_idx], df_y[train_idx])\n",
    "\n",
    "df_X_t = pipeline.transform(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations size: 1\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [256]  # 128, 256, 512, 1024]\n",
    "\n",
    "batch_size = [48]  # [8, 16, 32, 64]\n",
    "\n",
    "depth = [3]  # [3, 4, 5]\n",
    "\n",
    "learning_rate = [0.0001]  # [0.001, 0.1]\n",
    "\n",
    "num_epochs = [200]\n",
    "\n",
    "\n",
    "def log_cosh_loss(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    def _log_cosh(x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + torch.nn.functional.softplus(-2.0 * x) - math.log(2.0)\n",
    "\n",
    "    return torch.mean(_log_cosh(y_pred - y_true))\n",
    "\n",
    "\n",
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def init(self):\n",
    "        super().init()\n",
    "\n",
    "    def forward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return log_cosh_loss(y_pred, y_true)\n",
    "\n",
    "\n",
    "criterion = [nn.MSELoss()]  # [nn.L1Loss(), nn.HuberLoss(), LogCoshLoss()] # MSELoss,\n",
    "\n",
    "optimizer = [RMSprop]  # Adam, SGD\n",
    "\n",
    "scheduler_patience = [7]\n",
    "scheduler_threshold = [2.0]\n",
    "\n",
    "early_stopper_patience = [10]\n",
    "\n",
    "momentum = [0.9]\n",
    "\n",
    "dropout_rate = [None]\n",
    "\n",
    "hyperparameters = list(\n",
    "    product(\n",
    "        hidden_size,\n",
    "        depth,\n",
    "        num_epochs,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler_patience,\n",
    "        scheduler_threshold,\n",
    "        momentum,\n",
    "        dropout_rate,\n",
    "        early_stopper_patience,\n",
    "    )\n",
    ")\n",
    "n_comb = len(hyperparameters)\n",
    "print(f\"Combinations size: {n_comb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================================\n",
      "Iteration 1/1\n",
      "ID                                      20240201-195210525\n",
      "R^2                                                   None\n",
      "MSE                                                   None\n",
      "preprocess                                          STD+L2\n",
      "NN_architecture           [Linear(hidden_size)+ReLU]*depth\n",
      "depth                                                    3\n",
      "hidden_size                                            256\n",
      "dropout_rate                                          None\n",
      "batch_size                                              48\n",
      "learning_rate                                       0.0001\n",
      "criterion                                        MSELoss()\n",
      "optimizer                                          RMSprop\n",
      "momentum                                               0.9\n",
      "scheduler_patience                                       7\n",
      "scheduler_threshold                                    2.0\n",
      "early_stopper_patience                                  10\n",
      "num_epochs                                             200\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_combination = None\n",
    "best_model = None\n",
    "\n",
    "results_tt = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"ID\",\n",
    "        \"R^2\",\n",
    "        \"MSE\",\n",
    "        \"preprocess\",\n",
    "        \"NN_architecture\",\n",
    "        \"depth\",\n",
    "        \"hidden_size\",\n",
    "        \"dropout_rate\",\n",
    "        \"batch_size\",\n",
    "        \"learning_rate\",\n",
    "        \"criterion\",\n",
    "        \"optimizer\",\n",
    "        \"momentum\",\n",
    "        \"scheduler_patience\",\n",
    "        \"scheduler_threshold\",\n",
    "        \"early_stopper_patience\",\n",
    "        \"num_epochs\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for n_iter, (\n",
    "    hidden_size,\n",
    "    depth,\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    learning_rate,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler_patience,\n",
    "    scheduler_threshold,\n",
    "    momentum,\n",
    "    dropout_rate,\n",
    "    early_stopper_patience,\n",
    ") in enumerate(hyperparameters):\n",
    "    fix_random(random_state)\n",
    "    print(\"\\n=================================================================================\")\n",
    "    print(f\"Iteration {n_iter+1}/{n_comb}\")\n",
    "\n",
    "    log_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\") + str(datetime.now().microsecond // 1000)\n",
    "    log_writer = SummaryWriter(runs_dir + log_name)\n",
    "\n",
    "    # Data Loaders\n",
    "    my_dataset = MyDataset(df_X_t, df_y)\n",
    "    train_loader = DataLoader(Subset(my_dataset, train_idx), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(Subset(my_dataset, val_idx), batch_size=1)\n",
    "    test_loader = DataLoader(Subset(my_dataset, test_idx), batch_size=1)\n",
    "\n",
    "    model = NeuralNetworkSimple(my_dataset.num_features, hidden_size, depth=depth)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, patience=scheduler_patience, threshold=scheduler_threshold, threshold_mode=\"abs\", verbose=True\n",
    "    )\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=early_stopper_patience, delta=0.1)\n",
    "\n",
    "    # Save configuration to df\n",
    "    results_tt.loc[len(results_tt)] = [\n",
    "        log_name,\n",
    "        None,\n",
    "        None,\n",
    "        preprocess_name,\n",
    "        model._get_description(),\n",
    "        depth,\n",
    "        hidden_size,\n",
    "        dropout_rate,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        criterion,\n",
    "        optimizer.__class__.__name__,\n",
    "        momentum,\n",
    "        scheduler_patience,\n",
    "        scheduler_threshold,\n",
    "        early_stopper_patience,\n",
    "        num_epochs,\n",
    "    ]\n",
    "    print(results_tt.loc[len(results_tt) - 1])\n",
    "\n",
    "    # Train\n",
    "    train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        scheduler,\n",
    "        early_stopper,\n",
    "        device,\n",
    "        log_writer,\n",
    "        log_name,\n",
    "    )\n",
    "\n",
    "    # Load best model (saven in the train function)\n",
    "    model.load_state_dict(torch.load(model_dir + log_name))\n",
    "    model.to(device)\n",
    "\n",
    "    # Test\n",
    "    y_true, y_pred = test_model(model, test_loader, device)\n",
    "    test_loss = criterion(y_pred, y_true)\n",
    "    print(f\"\\nTest loss (for given criterion): {test_loss:.4f}\")\n",
    "    r2 = r2_score(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "    mse = mean_squared_error(y_true.detach().numpy(), y_pred.detach().numpy())\n",
    "    print(f\"R^2: {r2:.4f}, MSE:{mse:.4f}\")\n",
    "\n",
    "    # Add results to df\n",
    "    results_tt.loc[len(results_tt) - 1, \"R^2\"] = r2\n",
    "    results_tt.loc[len(results_tt) - 1, \"MSE\"] = mse\n",
    "    results_tt.to_csv(\"2_output.csv\", mode=\"a\", index=False, header=False)\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_model = model\n",
    "        best_combination = results_tt.loc[len(results_tt) - 1]\n",
    "\n",
    "    log_writer.flush()\n",
    "    log_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination:\n",
      "ID                                      20240201-194336525\n",
      "R^2                                               0.338109\n",
      "MSE                                              72.946396\n",
      "preprocess                                          STD+L2\n",
      "NN_architecture           [Linear(hidden_size)+ReLU]*depth\n",
      "depth                                                    3\n",
      "hidden_size                                            256\n",
      "dropout_rate                                          None\n",
      "batch_size                                              48\n",
      "learning_rate                                       0.0001\n",
      "criterion                                        MSELoss()\n",
      "optimizer                                          RMSprop\n",
      "momentum                                               0.9\n",
      "scheduler_patience                                       7\n",
      "scheduler_threshold                                    1.0\n",
      "early_stopper_patience                                  10\n",
      "num_epochs                                             200\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Best combination:\")\n",
    "print(best_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_95944\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_95944_level0_col0\" class=\"col_heading level0 col0\" >ID</th>\n",
       "      <th id=\"T_95944_level0_col1\" class=\"col_heading level0 col1\" >R^2</th>\n",
       "      <th id=\"T_95944_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_95944_level0_col3\" class=\"col_heading level0 col3\" >preprocess</th>\n",
       "      <th id=\"T_95944_level0_col4\" class=\"col_heading level0 col4\" >NN_architecture</th>\n",
       "      <th id=\"T_95944_level0_col5\" class=\"col_heading level0 col5\" >depth</th>\n",
       "      <th id=\"T_95944_level0_col6\" class=\"col_heading level0 col6\" >hidden_size</th>\n",
       "      <th id=\"T_95944_level0_col7\" class=\"col_heading level0 col7\" >dropout_rate</th>\n",
       "      <th id=\"T_95944_level0_col8\" class=\"col_heading level0 col8\" >batch_size</th>\n",
       "      <th id=\"T_95944_level0_col9\" class=\"col_heading level0 col9\" >learning_rate</th>\n",
       "      <th id=\"T_95944_level0_col10\" class=\"col_heading level0 col10\" >criterion</th>\n",
       "      <th id=\"T_95944_level0_col11\" class=\"col_heading level0 col11\" >optimizer</th>\n",
       "      <th id=\"T_95944_level0_col12\" class=\"col_heading level0 col12\" >momentum</th>\n",
       "      <th id=\"T_95944_level0_col13\" class=\"col_heading level0 col13\" >scheduler_patience</th>\n",
       "      <th id=\"T_95944_level0_col14\" class=\"col_heading level0 col14\" >scheduler_threshold</th>\n",
       "      <th id=\"T_95944_level0_col15\" class=\"col_heading level0 col15\" >early_stopper_patience</th>\n",
       "      <th id=\"T_95944_level0_col16\" class=\"col_heading level0 col16\" >num_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_95944_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_95944_row0_col0\" class=\"data row0 col0\" >20240201-194336525</td>\n",
       "      <td id=\"T_95944_row0_col1\" class=\"data row0 col1\" >0.3381</td>\n",
       "      <td id=\"T_95944_row0_col2\" class=\"data row0 col2\" >72.9464</td>\n",
       "      <td id=\"T_95944_row0_col3\" class=\"data row0 col3\" >STD+L2</td>\n",
       "      <td id=\"T_95944_row0_col4\" class=\"data row0 col4\" >[Linear(hidden_size)+ReLU]*depth</td>\n",
       "      <td id=\"T_95944_row0_col5\" class=\"data row0 col5\" >3</td>\n",
       "      <td id=\"T_95944_row0_col6\" class=\"data row0 col6\" >256</td>\n",
       "      <td id=\"T_95944_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "      <td id=\"T_95944_row0_col8\" class=\"data row0 col8\" >48</td>\n",
       "      <td id=\"T_95944_row0_col9\" class=\"data row0 col9\" >0.0001</td>\n",
       "      <td id=\"T_95944_row0_col10\" class=\"data row0 col10\" >MSELoss()</td>\n",
       "      <td id=\"T_95944_row0_col11\" class=\"data row0 col11\" >RMSprop</td>\n",
       "      <td id=\"T_95944_row0_col12\" class=\"data row0 col12\" >0.9000</td>\n",
       "      <td id=\"T_95944_row0_col13\" class=\"data row0 col13\" >7</td>\n",
       "      <td id=\"T_95944_row0_col14\" class=\"data row0 col14\" >1.0000</td>\n",
       "      <td id=\"T_95944_row0_col15\" class=\"data row0 col15\" >10</td>\n",
       "      <td id=\"T_95944_row0_col16\" class=\"data row0 col16\" >200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f45b699be80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"2_output.csv\").sort_values(by=\"R^2\", ascending=False).style.format(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 72.946396\n",
      "R2: 0.33810887605500783\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = test_model(best_model, test_loader, device)\n",
    "\n",
    "mse = mean_squared_error(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "r2 = r2_score(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
