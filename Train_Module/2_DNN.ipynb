{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:38.127067100Z",
     "start_time": "2023-06-22T17:05:38.098187500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from itertools import product\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"2_NN_outputs/\"\n",
    "model_dir = base_dir + \"models/\"\n",
    "runs_dir = base_dir + \"runs/\"\n",
    "\n",
    "# shutil.rmtree(model_dir, ignore_errors=True)\n",
    "# shutil.rmtree(runs_dir, ignore_errors=True)\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "# os.makedirs(runs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, fix all the seeds\n",
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    # Save X and y as Tensors, accordingly to the type of the data\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "\n",
    "        self.num_features = X.shape[1]\n",
    "\n",
    "    # Dataset size\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx, :], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.070805500Z",
     "start_time": "2023-06-22T17:05:42.065927700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, depth):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            *[\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "            * (depth - 1)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_in = self.input_layer(x)\n",
    "        h_out = self.hidden_layers(h_in)\n",
    "        out = self.output(h_out)\n",
    "        return out\n",
    "\n",
    "    def _get_description(self):\n",
    "        return \"Linear(all same size)+ReLU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, delta=0):\n",
    "        self.patience: int = patience\n",
    "        self.delta: int = delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float(\"inf\")\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss <= (self.min_validation_loss - self.delta):\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            return False\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            # print(\"\\tEarly stopper: {}/{} epochs\".format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.116054200Z",
     "start_time": "2023-06-22T17:05:42.087104900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for the training process\n",
    "def train_model(\n",
    "    model: nn.Module,  # instance of class to train\n",
    "    criterion,  # instance of loss function\n",
    "    optimizer,  # instance of optimizer\n",
    "    epochs,  # number of\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    scheduler,\n",
    "    device,  # to train on\n",
    "    log_writer,\n",
    "    log_name,\n",
    "):\n",
    "    n_iter = 0\n",
    "    best_valid_loss = float(\"inf\")  # initialized to worst possible value\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=10, delta=0.1)\n",
    "\n",
    "    # EPOCHS\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # activate training mode (for BatchNorm or Dropout)\n",
    "\n",
    "        # BATCHES\n",
    "        for data, targets in train_loader:  # get_item from MyDataset class (single item or batch)\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # gradient to zero\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(data)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred.squeeze(), targets)  # reshape because MSELoss requires same dimensionality\n",
    "            log_writer.add_scalar(\"Loss train/batches\", loss, n_iter)  # plot the batches\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "        # Valuation\n",
    "        y_test, y_pred = test_model(model, val_loader, device)\n",
    "        loss_val = criterion(y_pred.squeeze(), y_test)\n",
    "        log_writer.add_scalar(\"Loss val/epochs\", loss_val, epoch)  # plot the epochs\n",
    "\n",
    "        scheduler.step(loss_val)\n",
    "\n",
    "        # Save the model with best loss through the epochs\n",
    "        if loss_val.item() < best_valid_loss:\n",
    "            best_valid_loss = loss_val.item()\n",
    "            torch.save(model.state_dict(), model_dir + log_name)\n",
    "\n",
    "        # Early Stopping\n",
    "        if early_stopper.early_stop(loss_val.item()):\n",
    "            print(\"Early stopped!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.116054200Z",
     "start_time": "2023-06-22T17:05:42.106079700Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(model: nn.Module, data_loader: DataLoader, device) -> tuple[Tensor, Tensor, Tensor]:\n",
    "    model.eval()  # activate evaluation mode (for BatchNorm or Dropout)\n",
    "\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "\n",
    "    for data, targets in data_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        y_pred.append(model(data))  # accumulate predictions\n",
    "        y_test.append(targets)  # accumulate labels\n",
    "\n",
    "    y_test = torch.stack(y_test).squeeze()\n",
    "    y_pred = torch.stack(y_pred).squeeze()\n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:40.242589800Z",
     "start_time": "2023-06-22T17:05:38.117070300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  252123\n",
      "Columns:  91\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\").drop_duplicates()\n",
    "print(\"Rows: \", df.shape[0])\n",
    "print(\"Columns: \", df.shape[1])\n",
    "\n",
    "df_X = df.iloc[:, 1:].values\n",
    "df_y = df.iloc[:, 0].values\n",
    "indices = np.arange(df_X.shape[0])\n",
    "\n",
    "# Separate indices in train/val/set\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.2, stratify=df_y, random_state=random_state)\n",
    "train_idx, val_idx = train_test_split(train_idx, test_size=0.2, stratify=df_y[train_idx], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T17:05:42.056143500Z",
     "start_time": "2023-06-22T17:05:40.565714200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.covariance import OAS\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([(\"raw\", None)])\n",
    "preprocess_name = \"RAW\"\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"std\", preprocessing.MinMaxScaler())\n",
    "#     ]\n",
    "# )\n",
    "# preprocess_name = \"STD\"\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"min-max\", preprocessing.MinMaxScaler()),\n",
    "#         (\"lmax\", preprocessing.Normalizer(norm=\"max\")),\n",
    "#         (\"lda\", LinearDiscriminantAnalysis(solver=\"eigen\", shrinkage=None, covariance_estimator=OAS())),\n",
    "#     ]\n",
    "# )\n",
    "# preprocess_name = \"MinMax+Lmax+LDA\"\n",
    "\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\"min-max\", preprocessing.MinMaxScaler()),\n",
    "#         (\"lda\", LinearDiscriminantAnalysis(solver=\"eigen\", covariance_estimator=OAS())),\n",
    "#         (\"nys\", Nystroem(random_state=random_state, n_jobs=-1, gamma=0.010, n_components=1000)),\n",
    "#     ]\n",
    "# )\n",
    "# preprocess_name = \"MinMax+LDA+NYS\"\n",
    "\n",
    "pipeline.fit(df_X[train_idx], df_y[train_idx])\n",
    "\n",
    "df_X_t = pipeline.transform(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations size: 1\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [256]  # 128, 256, 512, 1024]\n",
    "\n",
    "batch_size = [16]  # [8, 16, 32, 64]\n",
    "\n",
    "# dropout_p = [0.2, 0.3]  # 0.2\n",
    "\n",
    "depth = [3]  # [3, 4, 5]\n",
    "\n",
    "learning_rate = [0.1]  # [0.001, 0.1]\n",
    "\n",
    "num_epochs = [2]\n",
    "\n",
    "# It is mathematically the preferred loss function under the inference framework of maximum likelihood if the distribution of the target variable is Gaussian.\n",
    "criterion = [nn.MSELoss()]\n",
    "## provare anche\n",
    "# Mean Absolute Error (MAE) -> less sensitive to outliers\n",
    "# Huber Loss -> combination of MAE\n",
    "# Log-Cosh Loss -> smooth approximation of the MAE loss function. It is less sensitive to outliers than MSE and more robust than MAE.\n",
    "\n",
    "# optimizer = torch.optim.SGD\n",
    "optimizer = [torch.optim.Adam]\n",
    "# Momentum\n",
    "# RMSprop\n",
    "\n",
    "scheduler_patience = [5]\n",
    "scheduler_threshold = [1.0]\n",
    "\n",
    "\n",
    "hyperparameters = list(\n",
    "    product(\n",
    "        hidden_size,\n",
    "        depth,\n",
    "        num_epochs,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        scheduler_patience,\n",
    "        scheduler_threshold,\n",
    "    )\n",
    ")\n",
    "n_comb = len(hyperparameters)\n",
    "print(f\"Combinations size: {n_comb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================\n",
      "Iteration 1/1\n",
      "RAW--Linear(all same size)+ReLU--depth=3--hidden_size=256--batch_size=16--lr=0.1--sched_pat=5--sched_thr=1.0\n",
      "NeuralNetwork(\n",
      "  (input_layer): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (hidden_layers): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (output): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Test loss: 359249.6250\n",
      "R^2: -3259.7604, MSE:359249.6562\n"
     ]
    }
   ],
   "source": [
    "best_loss = np.inf\n",
    "best_combination = None\n",
    "best_model = None\n",
    "\n",
    "results_tt = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"R^2\",\n",
    "        \"MSE\",\n",
    "        \"preprocess\",\n",
    "        \"NN_architecture\",\n",
    "        \"depth\",\n",
    "        \"hidden_size\",\n",
    "        \"batch_size\",\n",
    "        \"learning_rate\",\n",
    "        \"num_epochs\",\n",
    "        \"criterion\",\n",
    "        \"optimizer\",\n",
    "        \"scheduler_patience\",\n",
    "        \"scheduler_threshold\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for n_iter, (\n",
    "    hidden_size,\n",
    "    depth,\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    learning_rate,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler_patience,\n",
    "    scheduler_threshold,\n",
    ") in enumerate(hyperparameters):\n",
    "    fix_random(random_state)\n",
    "    print(\"\\n===========================\")\n",
    "    print(f\"Iteration {n_iter+1}/{n_comb}\")\n",
    "\n",
    "    # Data Loaders\n",
    "    my_dataset = MyDataset(df_X_t, df_y)\n",
    "    train_loader = DataLoader(Subset(my_dataset, train_idx), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(Subset(my_dataset, val_idx), batch_size=1)\n",
    "    test_loader = DataLoader(Subset(my_dataset, test_idx), batch_size=1)\n",
    "\n",
    "    model = NeuralNetwork(my_dataset.num_features, hidden_size, depth=depth)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optimizer(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, patience=scheduler_patience, threshold=scheduler_threshold, verbose=True)\n",
    "\n",
    "    log_name = (\n",
    "        preprocess_name\n",
    "        + \"--\"\n",
    "        + model._get_description()\n",
    "        + \"--\"\n",
    "        + f\"depth={depth}--hidden_size={hidden_size}--batch_size={batch_size}--lr={learning_rate}\"\n",
    "        + \"--\"\n",
    "        + f\"sched_pat={scheduler_patience}--sched_thr={scheduler_threshold}\"\n",
    "    )\n",
    "    print(log_name)\n",
    "    print(model)\n",
    "    log_writer = SummaryWriter(runs_dir + log_name)\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        scheduler,\n",
    "        device,\n",
    "        log_writer,\n",
    "        log_name,\n",
    "    )\n",
    "\n",
    "    # Load best model (saven in the train function)\n",
    "    model.load_state_dict(torch.load(model_dir + log_name))\n",
    "    model.to(device)\n",
    "\n",
    "    # Test\n",
    "    y_true, y_pred = test_model(model, test_loader, device)\n",
    "    test_loss = criterion(y_pred, y_true)\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    mse = mean_squared_error(y_true.detach().numpy(), y_pred.detach().numpy())\n",
    "    r2 = r2_score(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "    print(f\"R^2: {r2:.4f}, MSE:{mse:.4f}\")\n",
    "\n",
    "    results_tt.loc[len(results_tt)] = [\n",
    "        r2,\n",
    "        mse,\n",
    "        preprocess_name,\n",
    "        model._get_description(),\n",
    "        depth,\n",
    "        hidden_size,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        num_epochs,\n",
    "        criterion,\n",
    "        optimizer.__class__.__name__,\n",
    "        scheduler_patience,\n",
    "        scheduler_threshold,\n",
    "    ]\n",
    "    results_tt.to_csv(\"2_output.csv\", mode=\"a\", index=False, header=False)\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_model = model\n",
    "        best_combination = results_tt.loc[len(results_tt) - 1]\n",
    "\n",
    "    log_writer.flush()\n",
    "    log_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination:\n",
      "R^2                                  -3259.760417\n",
      "MSE                                  359249.65625\n",
      "preprocess                                    RAW\n",
      "NN_architecture        Linear(all same size)+ReLU\n",
      "depth                                           3\n",
      "hidden_size                                   256\n",
      "batch_size                                     16\n",
      "learning_rate                                 0.1\n",
      "num_epochs                                      2\n",
      "criterion                               MSELoss()\n",
      "optimizer                                    Adam\n",
      "scheduler_patience                              5\n",
      "scheduler_threshold                           1.0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Best combination:\")\n",
    "print(best_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1854d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1854d_level0_col0\" class=\"col_heading level0 col0\" >R^2</th>\n",
       "      <th id=\"T_1854d_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_1854d_level0_col2\" class=\"col_heading level0 col2\" > preprocess</th>\n",
       "      <th id=\"T_1854d_level0_col3\" class=\"col_heading level0 col3\" >NN_architecture</th>\n",
       "      <th id=\"T_1854d_level0_col4\" class=\"col_heading level0 col4\" >depth</th>\n",
       "      <th id=\"T_1854d_level0_col5\" class=\"col_heading level0 col5\" >hidden_size</th>\n",
       "      <th id=\"T_1854d_level0_col6\" class=\"col_heading level0 col6\" >batch_size</th>\n",
       "      <th id=\"T_1854d_level0_col7\" class=\"col_heading level0 col7\" >learning_rate</th>\n",
       "      <th id=\"T_1854d_level0_col8\" class=\"col_heading level0 col8\" >num_epochs</th>\n",
       "      <th id=\"T_1854d_level0_col9\" class=\"col_heading level0 col9\" >criterion</th>\n",
       "      <th id=\"T_1854d_level0_col10\" class=\"col_heading level0 col10\" >optimizer</th>\n",
       "      <th id=\"T_1854d_level0_col11\" class=\"col_heading level0 col11\" >scheduler_patience</th>\n",
       "      <th id=\"T_1854d_level0_col12\" class=\"col_heading level0 col12\" > scheduler_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row0\" class=\"row_heading level0 row0\" >7</th>\n",
       "      <td id=\"T_1854d_row0_col0\" class=\"data row0 col0\" >-0.0000</td>\n",
       "      <td id=\"T_1854d_row0_col1\" class=\"data row0 col1\" >110.1737</td>\n",
       "      <td id=\"T_1854d_row0_col2\" class=\"data row0 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row0_col3\" class=\"data row0 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row0_col4\" class=\"data row0 col4\" >3</td>\n",
       "      <td id=\"T_1854d_row0_col5\" class=\"data row0 col5\" >256</td>\n",
       "      <td id=\"T_1854d_row0_col6\" class=\"data row0 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row0_col7\" class=\"data row0 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row0_col8\" class=\"data row0 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row0_col9\" class=\"data row0 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row0_col10\" class=\"data row0 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row0_col11\" class=\"data row0 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row0_col12\" class=\"data row0 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row1\" class=\"row_heading level0 row1\" >6</th>\n",
       "      <td id=\"T_1854d_row1_col0\" class=\"data row1 col0\" >-0.0000</td>\n",
       "      <td id=\"T_1854d_row1_col1\" class=\"data row1 col1\" >110.1737</td>\n",
       "      <td id=\"T_1854d_row1_col2\" class=\"data row1 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row1_col3\" class=\"data row1 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row1_col4\" class=\"data row1 col4\" >2</td>\n",
       "      <td id=\"T_1854d_row1_col5\" class=\"data row1 col5\" >256</td>\n",
       "      <td id=\"T_1854d_row1_col6\" class=\"data row1 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row1_col7\" class=\"data row1 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row1_col8\" class=\"data row1 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row1_col9\" class=\"data row1 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row1_col10\" class=\"data row1 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row1_col11\" class=\"data row1 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row1_col12\" class=\"data row1 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_1854d_row2_col0\" class=\"data row2 col0\" >-0.0000</td>\n",
       "      <td id=\"T_1854d_row2_col1\" class=\"data row2 col1\" >110.1747</td>\n",
       "      <td id=\"T_1854d_row2_col2\" class=\"data row2 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row2_col3\" class=\"data row2 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row2_col4\" class=\"data row2 col4\" >3</td>\n",
       "      <td id=\"T_1854d_row2_col5\" class=\"data row2 col5\" >128</td>\n",
       "      <td id=\"T_1854d_row2_col6\" class=\"data row2 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row2_col7\" class=\"data row2 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row2_col8\" class=\"data row2 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row2_col9\" class=\"data row2 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row2_col10\" class=\"data row2 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row2_col11\" class=\"data row2 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row2_col12\" class=\"data row2 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_1854d_row3_col0\" class=\"data row3 col0\" >-0.0000</td>\n",
       "      <td id=\"T_1854d_row3_col1\" class=\"data row3 col1\" >110.1747</td>\n",
       "      <td id=\"T_1854d_row3_col2\" class=\"data row3 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row3_col3\" class=\"data row3 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row3_col4\" class=\"data row3 col4\" >2</td>\n",
       "      <td id=\"T_1854d_row3_col5\" class=\"data row3 col5\" >128</td>\n",
       "      <td id=\"T_1854d_row3_col6\" class=\"data row3 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row3_col7\" class=\"data row3 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row3_col8\" class=\"data row3 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row3_col9\" class=\"data row3 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row3_col10\" class=\"data row3 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row3_col11\" class=\"data row3 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row4\" class=\"row_heading level0 row4\" >8</th>\n",
       "      <td id=\"T_1854d_row4_col0\" class=\"data row4 col0\" >-0.0002</td>\n",
       "      <td id=\"T_1854d_row4_col1\" class=\"data row4 col1\" >110.1991</td>\n",
       "      <td id=\"T_1854d_row4_col2\" class=\"data row4 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row4_col3\" class=\"data row4 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row4_col4\" class=\"data row4 col4\" >4</td>\n",
       "      <td id=\"T_1854d_row4_col5\" class=\"data row4 col5\" >256</td>\n",
       "      <td id=\"T_1854d_row4_col6\" class=\"data row4 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row4_col7\" class=\"data row4 col7\" >0.0500</td>\n",
       "      <td id=\"T_1854d_row4_col8\" class=\"data row4 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row4_col9\" class=\"data row4 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row4_col10\" class=\"data row4 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row4_col11\" class=\"data row4 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row4_col12\" class=\"data row4 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
       "      <td id=\"T_1854d_row5_col0\" class=\"data row5 col0\" >-0.0003</td>\n",
       "      <td id=\"T_1854d_row5_col1\" class=\"data row5 col1\" >110.2081</td>\n",
       "      <td id=\"T_1854d_row5_col2\" class=\"data row5 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row5_col3\" class=\"data row5 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row5_col4\" class=\"data row5 col4\" >3</td>\n",
       "      <td id=\"T_1854d_row5_col5\" class=\"data row5 col5\" >128</td>\n",
       "      <td id=\"T_1854d_row5_col6\" class=\"data row5 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row5_col7\" class=\"data row5 col7\" >0.0100</td>\n",
       "      <td id=\"T_1854d_row5_col8\" class=\"data row5 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row5_col9\" class=\"data row5 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row5_col10\" class=\"data row5 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row5_col11\" class=\"data row5 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row6\" class=\"row_heading level0 row6\" >4</th>\n",
       "      <td id=\"T_1854d_row6_col0\" class=\"data row6 col0\" >-0.0044</td>\n",
       "      <td id=\"T_1854d_row6_col1\" class=\"data row6 col1\" >110.6538</td>\n",
       "      <td id=\"T_1854d_row6_col2\" class=\"data row6 col2\" >MinMax+LDA+NYS</td>\n",
       "      <td id=\"T_1854d_row6_col3\" class=\"data row6 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row6_col4\" class=\"data row6 col4\" >3</td>\n",
       "      <td id=\"T_1854d_row6_col5\" class=\"data row6 col5\" >128</td>\n",
       "      <td id=\"T_1854d_row6_col6\" class=\"data row6 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row6_col7\" class=\"data row6 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row6_col8\" class=\"data row6 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row6_col9\" class=\"data row6 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row6_col10\" class=\"data row6 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row6_col11\" class=\"data row6 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row6_col12\" class=\"data row6 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row7\" class=\"row_heading level0 row7\" >3</th>\n",
       "      <td id=\"T_1854d_row7_col0\" class=\"data row7 col0\" >-0.0075</td>\n",
       "      <td id=\"T_1854d_row7_col1\" class=\"data row7 col1\" >110.9971</td>\n",
       "      <td id=\"T_1854d_row7_col2\" class=\"data row7 col2\" >MinMax+Lmax+LDA</td>\n",
       "      <td id=\"T_1854d_row7_col3\" class=\"data row7 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row7_col4\" class=\"data row7 col4\" >3</td>\n",
       "      <td id=\"T_1854d_row7_col5\" class=\"data row7 col5\" >128</td>\n",
       "      <td id=\"T_1854d_row7_col6\" class=\"data row7 col6\" >32</td>\n",
       "      <td id=\"T_1854d_row7_col7\" class=\"data row7 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row7_col8\" class=\"data row7 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row7_col9\" class=\"data row7 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row7_col10\" class=\"data row7 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row7_col11\" class=\"data row7 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row7_col12\" class=\"data row7 col12\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_1854d_row8_col0\" class=\"data row8 col0\" >-3259.7604</td>\n",
       "      <td id=\"T_1854d_row8_col1\" class=\"data row8 col1\" >359249.6600</td>\n",
       "      <td id=\"T_1854d_row8_col2\" class=\"data row8 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row8_col3\" class=\"data row8 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row8_col4\" class=\"data row8 col4\" >3</td>\n",
       "      <td id=\"T_1854d_row8_col5\" class=\"data row8 col5\" >256</td>\n",
       "      <td id=\"T_1854d_row8_col6\" class=\"data row8 col6\" >16</td>\n",
       "      <td id=\"T_1854d_row8_col7\" class=\"data row8 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row8_col8\" class=\"data row8 col8\" >2</td>\n",
       "      <td id=\"T_1854d_row8_col9\" class=\"data row8 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row8_col10\" class=\"data row8 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row8_col11\" class=\"data row8 col11\" >5.0000</td>\n",
       "      <td id=\"T_1854d_row8_col12\" class=\"data row8 col12\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1854d_level0_row9\" class=\"row_heading level0 row9\" >5</th>\n",
       "      <td id=\"T_1854d_row9_col0\" class=\"data row9 col0\" >-9324.5539</td>\n",
       "      <td id=\"T_1854d_row9_col1\" class=\"data row9 col1\" >1027429.5000</td>\n",
       "      <td id=\"T_1854d_row9_col2\" class=\"data row9 col2\" >RAW</td>\n",
       "      <td id=\"T_1854d_row9_col3\" class=\"data row9 col3\" >Linear(all same size)+ReLU</td>\n",
       "      <td id=\"T_1854d_row9_col4\" class=\"data row9 col4\" >2</td>\n",
       "      <td id=\"T_1854d_row9_col5\" class=\"data row9 col5\" >256</td>\n",
       "      <td id=\"T_1854d_row9_col6\" class=\"data row9 col6\" >8</td>\n",
       "      <td id=\"T_1854d_row9_col7\" class=\"data row9 col7\" >0.1000</td>\n",
       "      <td id=\"T_1854d_row9_col8\" class=\"data row9 col8\" >200</td>\n",
       "      <td id=\"T_1854d_row9_col9\" class=\"data row9 col9\" >MSELoss()</td>\n",
       "      <td id=\"T_1854d_row9_col10\" class=\"data row9 col10\" >Adam</td>\n",
       "      <td id=\"T_1854d_row9_col11\" class=\"data row9 col11\" >nan</td>\n",
       "      <td id=\"T_1854d_row9_col12\" class=\"data row9 col12\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f95bf7d81f0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"2_output.csv\").sort_values(by=\"R^2\", ascending=False).style.format(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 359249.66\n",
      "R2: -2678759568818.217\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = test_model(best_model, test_loader, device)\n",
    "\n",
    "mse = mean_squared_error(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "r2 = r2_score(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
