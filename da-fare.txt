TO-DO list

--> CLASSIC ML
- far ripartire i test sui nuovi parametri
- LR: provare a usare un train più piccolo per capire i migliori parametri, poi su quelli fare un train finale e salvare
- RF: provare ad aumentare il numero di alberi (tipo 500) ma diminuire la % di sample per albero, per capire i migliori parametri, poi su quelli fare un train finale (con tipo 100 alberi e 100% di sample ad albero) e salvare
- KNN da valuare ancora
- SVM uguale a LR perché non fa nulla neanche con parametri di base



--> DECIDERE IN DNN
- PREPROCESS
- DIRECTORY
- OPTIMIZER
- LOSS FUNCTION
- HYPERPARAMETERS